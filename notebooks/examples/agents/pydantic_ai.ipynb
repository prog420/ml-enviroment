{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12468dcd-625f-4300-8f83-992a6b6ccced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── data models -------------------------------------------------------------\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "\n",
    "# ── agent -------------------------------------------------------------------\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cb6a3d7-f6b3-469d-8550-816e9735cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Issue(BaseModel):\n",
    "    line: int = Field(..., description=\"line number (1-based)\")\n",
    "    severity: Literal[\"info\", \"warning\", \"error\"]\n",
    "    message: str\n",
    "    suggestion: str\n",
    "\n",
    "class ReviewResult(BaseModel):\n",
    "    summary: str\n",
    "    issues: List[Issue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1104b0fd-be44-414b-98a7-1a00d106b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provider that talks to llama-cpp\n",
    "llama = OpenAIProvider(\n",
    "    base_url=\"http://llama_cpp:8000/v1\",\n",
    "    api_key=\"local\",\n",
    ")\n",
    "\n",
    "model = OpenAIModel(\n",
    "    \"Nous-Hermes-2-DPO_into_Nous_Hermes-2-Pro.Q8_0.gguf\", \n",
    "    provider=llama,\n",
    ")\n",
    "\n",
    "reviewer = Agent(\n",
    "    model,\n",
    "    output_type=ReviewResult,\n",
    "    instructions=(\n",
    "        \"You are a senior Python engineer. \"\n",
    "        \"Act as a strict code reviewer:\\n\"\n",
    "        \"1. Read the code the user sends.\\n\"\n",
    "        \"2. List all PEP-8, type, logic and functional problems.\\n\"\n",
    "        \"3. Suggest concrete improvements.\\n\"\n",
    "        \"Return **only** JSON that matches the ReviewResult schema.\"\n",
    "    ),\n",
    "    # model_settings={\n",
    "    #     \"temperature\": 0.6,   # more deterministic than the default 0.7\n",
    "    #     \"top_p\": 0.95,        # nucleus sampling – don’t set if you’re using temperature\n",
    "    #     \"max_tokens\": 2048,    # example of another setting you can pass\n",
    "    # },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4f1fa1-b6af-4495-9adc-da43b3f76aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── review some code --------------------------------------------------------\n",
    "code = \"\"\"\n",
    "def ADD(a: int,b: str):\n",
    "  return a -  b\n",
    "\"\"\"\n",
    "\n",
    "result = await reviewer.run(code)      # top-level await works in Jupyter ≥7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58ce03d-1748-471b-964e-16d3d669d910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.output.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
