{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5a0f37-7109-4881-b1a4-48844d7f4626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd940be0-1847-4865-b61d-592d14cc2bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 1: Define Output Schema ─────────────────────────────────────────\n",
    "class Issue(BaseModel):\n",
    "    line: int = Field(..., description=\"line number (1-based)\")\n",
    "    severity: Literal[\"info\", \"warning\", \"error\"]\n",
    "    message: str\n",
    "    suggestion: str\n",
    "\n",
    "class ReviewResult(BaseModel):\n",
    "    summary: str\n",
    "    issues: List[Issue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530712c5-de12-4c52-b5cd-b3e3321ddf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 2: Connect to Local LLM (llama-cpp) ─────────────────────────────\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"http://llama_cpp:8000/v1\",\n",
    "    api_key=\"local\",\n",
    "    model=\"Nous-Hermes-2-DPO_into_Nous_Hermes-2-Pro.Q8_0.gguf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4687445-3b19-4391-a64a-208ec193a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 3: Build Prompt & Output Parser ─────────────────────────────────\n",
    "parser = PydanticOutputParser(pydantic_object=ReviewResult)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"You are a senior Python engineer. Act as a strict code reviewer.\\n\"\n",
    "     \"Instructions:\\n\"\n",
    "     \"1. Read the code the user sends.\\n\"\n",
    "     \"2. List any PEP 8, type-safety or design problems.\\n\"\n",
    "     \"3. Suggest concrete improvements.\\n\"\n",
    "     \"Return **only** JSON that matches the ReviewResult schema.\"),\n",
    "    (\"user\", \"{code}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f9dc3-fcc8-4809-b419-b2037a05786d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 4: Create Structured Output Chain ───────────────────────────────\n",
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59b63cc-c7c5-49ab-a409-36df57f69ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 5: Call Agent on Sample Code ────────────────────────────────────\n",
    "async def run_code_review():\n",
    "    code_snippet = \"\"\"\n",
    "def ADD(a: int,b: str):\n",
    "  return a -  b\n",
    "\"\"\"\n",
    "    result: ReviewResult = await chain.ainvoke({\"code\": code_snippet})\n",
    "    print(result.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a784655a-4769-420c-b5e5-e8cc19fe1e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Step 6: Run (Jupyter-compatible) ─────────────────────────────────────\n",
    "await run_code_review()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
